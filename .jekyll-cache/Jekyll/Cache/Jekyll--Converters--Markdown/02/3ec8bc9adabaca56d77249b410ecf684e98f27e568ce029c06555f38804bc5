I"¢5<h1 id="what-is-docker">What is Docker?</h1>

<p>Docker is a form ofÂ OS-level virtualisationÂ whoseÂ purposeÂ is, to quote:</p>
<blockquote>
  <p>Package up code and all its dependencies so the application runs quickly and reliably from one computing environment to another</p>
</blockquote>

<hr />

<h1 id="why-docker">Why Docker?</h1>

<ul>
  <li>
    <p><strong>Speed</strong>: isolated, consistent and repeatable environments
for your developers to fire up a new version of the application that a collogue may have written requires muddling around in Git and using branches â€“ this interrupts work flows and can lead to lose of work if â€œgit stashâ€ isnâ€™t used right. With a container: they just run it.</p>
  </li>
  <li>
    <p><strong>Portability</strong>: Docker images define abstract and immutable run time environment independent of the underlying hardware platform and packages it into a well defined and efficient image specification. With Dockerhub, we have a global distribution network
First up: portability and allowing anyone, on any hardware, and any OS to run the application with a single command. All they need to do is install Docker and â€œdocker runâ€ will do the rest. With a TAR file based deployment, they need TAR, they need to know how-to deploy the application and manage the files; they may need some runtime on their system like Ruby, Python or NodeJS; and they cannot restrict the resources the application is usingâ€¦</p>
  </li>
  <li>
    <p><strong>Simplifies your infrastructure requirements</strong>
you can restrict the resources the application is using inside of a container much easier than you can with one that is not.</p>
  </li>
  <li>
    <p><strong>Automation</strong> is first class citizen: Dockerfile, DockerCompose
one final point here: Docker Compose. Youâ€™re missing out on a lot of free stuff here. Itâ€™s so easy to write a Docker Compose file that brings up everything needed by the application - databases, caches, mocked APIs - allowing anyone in your organisation to bring up the application on their laptop and play with it, including the CEO, DBAs, QA, the receptionist.â€¨</p>
  </li>
</ul>

<p>Example: You donâ€™t have to do these things (installing build tools, dependencies to build an application) on every new deployment! Instead you can build the applicationone and distribute it as an â€œexecutableâ€ (without the build tools and dependencies)</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Source Openrc-hgi.sh
Install python3
Install pip
Install setuptools wheel 
Pip install -r requirements.txt (openstack, dateutil, json,â€¦.)
Npm install (vue, bootstrapvue, â€¦)
</code></pre></div></div>
<hr />

<h1 id="cheatsheet">Cheatsheet</h1>

<p><strong>For deployment of code</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker build <span class="nt">-t</span> mercury/openstack_report_backend:prod <span class="nb">.</span>
docker login <span class="nt">--username</span><span class="o">=</span>mercury <span class="nt">--password</span><span class="o">=</span>jIJ43peAINdU
docker push  mercury/openstack_report_backend:prod

<span class="c"># You need to tag your image correctly first with yourÂ registryhost:</span>
docker tag <span class="o">[</span>OPTIONS] IMAGE[:TAG] <span class="o">[</span>REGISTRYHOST/][USERNAME/]NAME[:TAG]
<span class="c">#Then docker push using that same tag.</span>
docker push NAME[:TAG]

docker tag 518a41981a6a myRegistry.com/myImage
docker push myRegistry.com/myImage
</code></pre></div></div>

<p><strong>For debugging</strong></p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c"># You can see a list of your running containers with the command,Â docker ps, just as you would in Linux.</span>
docker ps

docker ps <span class="nt">-a</span> <span class="nt">-q</span> 
<span class="c"># -qÂ prints just the container ids (without column headers)</span>
<span class="c"># -fÂ allows you to filter your list of printed containers (in this case we are filtering to only show exited containers) </span>
<span class="c"># -vÂ to avoid dangling volumes</span>


journalctl <span class="nt">-u</span> docker.service | <span class="nb">tail</span> <span class="nt">-n</span> 50 

<span class="c"># to get a bash shell in a container </span>
dockerÂ exec <span class="nt">-it</span> &lt;containerÂ name&gt; /bin/bash 


<span class="c"># Example:  to get environmental variables</span>
docker <span class="nb">exec </span>container bash <span class="nt">-c</span> <span class="s1">'echo "$ENV_VAR"'</span>
docker <span class="nb">exec </span>container <span class="nb">printenv </span>VARIABLE

docker inspect &lt;container name&gt;

<span class="c"># You can display the long-form Id for a container with the command:</span>
docker inspect <span class="nt">--format</span> <span class="s1">'{{ .Id }}&gt;'</span> &lt;container name&gt;

<span class="c"># in a swarm </span>
docker service logs â€”details <span class="nt">--tail</span> 10 &lt;service name&gt;
docker service ps <span class="nt">--no-trunc</span> <span class="c"># to find out which node the service is running on</span>
docker service ps my-ngx <span class="c"># returns a task id</span>

docker service inspect <span class="nt">--pretty</span> &lt;SERVICE-ID&gt;
<span class="c"># to get the container id</span>
docker inspect <span class="nt">-f</span> <span class="s2">"{{.Status.ContainerStatus.ContainerID}}"</span> &lt;task_id&gt; 



<span class="c"># exec inside a swarm service</span>

docker <span class="nb">exec</span> <span class="nt">-it</span> <span class="si">$(</span>docker ps <span class="nt">--filter</span> <span class="s2">"name=my-service."</span> <span class="nt">-q</span><span class="si">)</span> <span class="nb">cat</span> /run/secrets/my-service-secret


</code></pre></div></div>

<p><strong>For Cleanup</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># This will remove all stopped containers and should work on all platforms the same way.</span>
docker container prune

<span class="c"># To  clean up all unused containers, networks, images (both dangling and unreferenced), and optionally, volumes, in one command.will delete ALL unused data (i.e., in order: containers stopped, volumes without containers and images with no containers).</span>
docker system pruneÂ 

docker <span class="nb">rm</span> <span class="sb">`</span>docker ps <span class="nt">--no-trunc</span> <span class="nt">-aq</span><span class="sb">`</span>
docker <span class="nb">rm</span> <span class="si">$(</span>docker ps <span class="nt">-a</span> <span class="nt">-q</span> <span class="nt">--no-trunc</span><span class="si">)</span> <span class="c"># to avoid id clashes </span>
docker ps <span class="nt">-a</span> <span class="nt">-q</span> | xargs docker <span class="nb">rm  
</span>docker <span class="nb">rm</span> <span class="nt">-v</span> <span class="si">$(</span>docker ps <span class="nt">-q</span> <span class="nt">-f</span> <span class="nv">status</span><span class="o">=</span>exited<span class="si">)</span>
docker <span class="nb">rm</span> <span class="si">$(</span>docker ps <span class="nt">-v</span> <span class="nt">-q</span> <span class="nt">-f</span>  <span class="nv">status</span><span class="o">=</span>exited<span class="si">)</span>  

</code></pre></div></div>
<hr />

<h1 id="the-language-of-docker">The language of Docker</h1>

<p>Image
Container: a running image
Service: a group of containers representing the same function (e.g. container replicas in a swarm)
Stack: a group of services + networks  + volumes
Node: a networking address: could be a container, a host etc.
Swarm: a group of nodes acting as one
Task
Config 
ï¿¼</p>

<p>Service vs Container vs Task</p>

<p>Services and container are related but both are different things.
A service can be run by one or multiple containers. WithÂ dockerÂ you can handle containers and withÂ docker-composeÂ you can handle services.
For example:
Letâ€™s say that we have thisÂ docker-compose.ymlÂ file:
web:
  image: example/my_web_app:latest
  expose:
    - 80
  links:
    - db</p>

<p>db:
  image: postgres:latest
This compose file defines two services,Â webÂ andÂ db.
When you runÂ docker-compose up, Asuming that the project directory isÂ test1Â then compose will start 2 containers namedÂ myapp_db_1Â andÂ myapp_web_1.
$ docker ps -a
CONTAINER ID   IMAGE        COMMAND          â€¦      NAMES
1c1683e871dc   test1_web    â€œnginx -gâ€       â€¦      test1_web_1
a41360558f96   test1_db     â€œpostgres -dâ€    â€¦      test1_db_1
So, in this point you have 2 services and 1 container for each.
But you could scale the service namedÂ webÂ to use 5 containers.
$ docker-compose scale web=5
Creating and starting 2 â€¦ done
Creating and starting 3 â€¦ done
Creating and starting 4 â€¦ done
Creating and starting 5 â€¦ done
In this point you have 2 services and 6 containers</p>

<p><strong>AnÂ image</strong>Â is an executable package that includes everything needed to run an applicationâ€“the code, a runtime, libraries, environment variables, and configuration files.</p>

<p><strong>AÂ container</strong> is a runtime instance of an imageâ€“what the image becomes in memory when executed (that is, an image with state, or a user process).  A container is launched by running an image.</p>

<p>Docker images are stored as series of read-only layers. When we start a container, Docker takes the read-only image and adds a read-write layer on top.Â  Images are frozen immutable snapshots of live containers. Containers are running (or stopped) instances of some image. <a href="https://stackoverflow.com/questions/21498832/in-docker-whats-the-difference-between-a-container-and-an-image">Image vs Container</a></p>

<p><strong>AÂ TaskÂ definition</strong>Â is a collection of 1 or moreÂ containerÂ configurations. Some Tasks may need only one container, while other Tasks may need 2 or more potentially linked containers running concurrently. The Task definition allows you to specify which Docker image to use, which ports to expose, how much CPU and memory to allot, how to collect logs, and define environment variables.</p>

<p><strong>AÂ Task</strong>Â is created when you run a Task directly, which launches container(s) (defined in the task definition) until they are stopped or exit on their own, at which point they areÂ not replaced automatically. Running Tasks directly is ideal for short running jobs, perhaps as an example things that were accomplished via CRON.</p>

<p><strong>AÂ service</strong>Â is used to guarantee that you always have some number of TasksÂ running at all times. If a Taskâ€™s container exits due to error, or the underlying EC2 instance fails and is replaced, the ECS Service will replace the failed Task. This is why we createÂ ClustersÂ so that the Service has plenty of resources in terms of CPU, Memory and Network ports to use. To us it doesnâ€™t really matter which instance Tasks run on so long as they run. A Service configurationÂ referencesÂ a Task definition. A Service is responsible forÂ creating Tasks.</p>

<p>Services are typically used for long running applications like web servers. For example, if I deployed my website powered by Node.JS in Oregon (us-west-2) I would want say at least three Tasks running across the three Availability Zones (AZ) for the sake of High-Availability; if one fails I have another two and the failed one will be replaced (read that asÂ self-healing!). Creating a Service is the way to do this. If I had 6 EC2 instances in my cluster, 2 per AZ, the Service will automatically balance Tasks across zones as best it can while also considering cpu, memory, and network resources.</p>

<p>UPDATE:
Iâ€™m not sure it helps to think of these things hierarchically.
Another very important point is that a Service can be configured to use a load balancer, so that as it creates the Tasksâ€”that is it launches containers defined in the Task Defintionâ€”the Service will automatically register the containerâ€™s EC2 instance with the load balancer. Tasks cannot be configured to use a load balancer, only Services can.</p>

<hr />

<p><strong>Useful Reads</strong></p>

<p>itd: <a href="https://stackoverflow.com/questions/30137135/confused-about-docker-t-option-to-allocate-a-pseudo-tty">Docker -it flags</a></p>

<ul>
  <li>
    <p>-iÂ (interactive) is about whether to keep stdin open (some programs, like bash, use stdin and other programs donâ€™t).Â </p>
  </li>
  <li>-dÂ (detached) is about whether theÂ docker runÂ command waits for the process being run to exit. Thus, they are orthogornal and not inherently contradictory. A program like bash exits when stdin in closed, so withoutÂ -i, it exits immediately.</li>
  <li></li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>-tÂ allocates a pseudo-tty. You can see the difference from running bash withÂ -itÂ vs with justÂ -i. For example, without -t, you donâ€™t get any prompt andÂ lsÂ shows results in one column. This difference is like the difference between runningÂ lsÂ and runningÂ ls</td>
          <td>cat, whereÂ catÂ does not have a pseudo-tty.</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>When youÂ docker runÂ bash in a container,Â -itÂ andÂ -itdÂ behave differently as follows:</li>
  <li>WithÂ -it,Â docker runÂ gives you the bash prompt immediately.</li>
  <li>WithÂ -itd,Â docker runÂ exits immediately, but you canÂ docker attachÂ after that and get the bash prompt just as if you had just doneÂ docker run -it.</li>
</ul>

:ET